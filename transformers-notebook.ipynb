{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-29T08:47:03.664523Z","iopub.execute_input":"2024-01-29T08:47:03.664960Z","iopub.status.idle":"2024-01-29T08:47:09.023686Z","shell.execute_reply.started":"2024-01-29T08:47:03.664934Z","shell.execute_reply":"2024-01-29T08:47:09.022721Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:09.025430Z","iopub.execute_input":"2024-01-29T08:47:09.025949Z","iopub.status.idle":"2024-01-29T08:47:12.281233Z","shell.execute_reply.started":"2024-01-29T08:47:09.025915Z","shell.execute_reply":"2024-01-29T08:47:12.280199Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"089b297f60554803bbb8265495a59643"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"806bf991c4c44eb4b3b792cd2e704aed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07ebfacd85d842f885e3780ed4e63be9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49859ae18ecb49a885d657cc28dd1c92"}},"metadata":{}}]},{"cell_type":"code","source":"\nsequence = \"I've been waiting for a HuggingFace course my whole life.\"\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:12.282580Z","iopub.execute_input":"2024-01-29T08:47:12.283215Z","iopub.status.idle":"2024-01-29T08:47:12.287919Z","shell.execute_reply.started":"2024-01-29T08:47:12.283179Z","shell.execute_reply":"2024-01-29T08:47:12.286937Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokens = tokenizer.tokenize(sequence)\nids = tokenizer.convert_tokens_to_ids(tokens)\nids\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:12.290107Z","iopub.execute_input":"2024-01-29T08:47:12.290594Z","iopub.status.idle":"2024-01-29T08:47:12.307599Z","shell.execute_reply.started":"2024-01-29T08:47:12.290568Z","shell.execute_reply":"2024-01-29T08:47:12.306762Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[1045,\n 1005,\n 2310,\n 2042,\n 3403,\n 2005,\n 1037,\n 17662,\n 12172,\n 2607,\n 2026,\n 2878,\n 2166,\n 1012]"},"metadata":{}}]},{"cell_type":"code","source":"input_ids = torch.tensor([ids])\nprint(\"Input IDs:\", input_ids)\n\noutput = model(input_ids)\nprint(\"Logits:\", output.logits)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:12.308511Z","iopub.execute_input":"2024-01-29T08:47:12.308758Z","iopub.status.idle":"2024-01-29T08:47:12.741225Z","shell.execute_reply.started":"2024-01-29T08:47:12.308735Z","shell.execute_reply":"2024-01-29T08:47:12.740172Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Input IDs: tensor([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n          2026,  2878,  2166,  1012]])\nLogits: tensor([[-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"seq1=[500,200,3000,4200,40]\nseq2=[32,455,678]","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:12.742555Z","iopub.execute_input":"2024-01-29T08:47:12.742921Z","iopub.status.idle":"2024-01-29T08:47:12.747950Z","shell.execute_reply.started":"2024-01-29T08:47:12.742892Z","shell.execute_reply":"2024-01-29T08:47:12.746896Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"seq3=seq2+[tokenizer.pad_token_id]*2","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:12.749299Z","iopub.execute_input":"2024-01-29T08:47:12.749599Z","iopub.status.idle":"2024-01-29T08:47:12.758898Z","shell.execute_reply.started":"2024-01-29T08:47:12.749567Z","shell.execute_reply":"2024-01-29T08:47:12.758007Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"seq2,seq3","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:12.760028Z","iopub.execute_input":"2024-01-29T08:47:12.762124Z","iopub.status.idle":"2024-01-29T08:47:12.770679Z","shell.execute_reply.started":"2024-01-29T08:47:12.762087Z","shell.execute_reply":"2024-01-29T08:47:12.769843Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"([32, 455, 678], [32, 455, 678, 0, 0])"},"metadata":{}}]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:12.771652Z","iopub.execute_input":"2024-01-29T08:47:12.771964Z","iopub.status.idle":"2024-01-29T08:47:12.780465Z","shell.execute_reply.started":"2024-01-29T08:47:12.771922Z","shell.execute_reply":"2024-01-29T08:47:12.779720Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model(torch.tensor([seq2])).logits","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:12.784447Z","iopub.execute_input":"2024-01-29T08:47:12.784735Z","iopub.status.idle":"2024-01-29T08:47:12.819869Z","shell.execute_reply.started":"2024-01-29T08:47:12.784711Z","shell.execute_reply":"2024-01-29T08:47:12.819003Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([[ 1.0102, -0.9595]], grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"model(torch.tensor([seq3])).logits","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:12.820986Z","iopub.execute_input":"2024-01-29T08:47:12.821259Z","iopub.status.idle":"2024-01-29T08:47:12.857616Z","shell.execute_reply.started":"2024-01-29T08:47:12.821235Z","shell.execute_reply":"2024-01-29T08:47:12.856678Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.8942, -0.8453]], grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"attention_mask=[1,1,1,0,0]","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:12.858759Z","iopub.execute_input":"2024-01-29T08:47:12.859088Z","iopub.status.idle":"2024-01-29T08:47:12.863570Z","shell.execute_reply.started":"2024-01-29T08:47:12.859062Z","shell.execute_reply":"2024-01-29T08:47:12.862514Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**now time to give the attention mask to make padded effect zero otherwise model will take pad as token**","metadata":{}},{"cell_type":"code","source":"model(input_ids=torch.tensor([seq3]),attention_mask=torch.tensor([attention_mask])).logits","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:12.864711Z","iopub.execute_input":"2024-01-29T08:47:12.865043Z","iopub.status.idle":"2024-01-29T08:47:12.904639Z","shell.execute_reply.started":"2024-01-29T08:47:12.865017Z","shell.execute_reply":"2024-01-29T08:47:12.903691Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"tensor([[ 1.0102, -0.9595]], grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"model(torch.tensor([seq2])).logits","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:12.906585Z","iopub.execute_input":"2024-01-29T08:47:12.907238Z","iopub.status.idle":"2024-01-29T08:47:12.934559Z","shell.execute_reply.started":"2024-01-29T08:47:12.907200Z","shell.execute_reply":"2024-01-29T08:47:12.933636Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"tensor([[ 1.0102, -0.9595]], grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"batched_ids_1 = [\n    [200, 200, 200],\n    [200, 200],\n]\n\ntorch.tensor(batched_ids_1)  ","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:12.935646Z","iopub.execute_input":"2024-01-29T08:47:12.935930Z","iopub.status.idle":"2024-01-29T08:47:13.518472Z","shell.execute_reply.started":"2024-01-29T08:47:12.935906Z","shell.execute_reply":"2024-01-29T08:47:13.514143Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m batched_ids_1 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     [\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m      3\u001b[0m     [\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m      4\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_ids_1\u001b[49m\u001b[43m)\u001b[49m  \n","\u001b[0;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 2)"],"ename":"ValueError","evalue":"expected sequence of length 3 at dim 1 (got 2)","output_type":"error"}]},{"cell_type":"markdown","source":"**batched_ids_1 = [\n    [200, 200, 200],\n    [200, 200],\n]\n\ntorch.tensor(batched_ids_1)  will not work because tensor works with rectangular batch size\n\n\nso we need to pad batch\n\nbatched_ids_1 = [\n    [200, 200, 200],\n    [200, 200, tokenizer.pad_token_id]\n]**","metadata":{}},{"cell_type":"markdown","source":"**tranformers tokenizers does all the work automatcially so we don't need to work as above********","metadata":{}},{"cell_type":"code","source":"query=['this is cow and cow is a animal','not the answer we want but still']\ninput=tokenizer(query,padding='longest',truncation=True,max_length=26,return_tensors=\"pt\")\ninput.get('input_ids')","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.519171Z","iopub.status.idle":"2024-01-29T08:47:13.519505Z","shell.execute_reply.started":"2024-01-29T08:47:13.519338Z","shell.execute_reply":"2024-01-29T08:47:13.519354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**.tokenizer(seq) are different then .convert_tokens_to_ids(tokens)\nfor .tokenizer() one tokenid {special token} added to front and one at the rear**","metadata":{}},{"cell_type":"code","source":"orignal_input=tokenizer.decode(input[\"input_ids\"][1])\norignal_input","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.520866Z","iopub.status.idle":"2024-01-29T08:47:13.521200Z","shell.execute_reply.started":"2024-01-29T08:47:13.521034Z","shell.execute_reply":"2024-01-29T08:47:13.521050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output=model(**input)\noutput","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.522295Z","iopub.status.idle":"2024-01-29T08:47:13.522855Z","shell.execute_reply.started":"2024-01-29T08:47:13.522460Z","shell.execute_reply":"2024-01-29T08:47:13.522476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prob=torch.sigmoid(output.logits)\nprob","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.524916Z","iopub.status.idle":"2024-01-29T08:47:13.525240Z","shell.execute_reply.started":"2024-01-29T08:47:13.525078Z","shell.execute_reply":"2024-01-29T08:47:13.525093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**#=================================================================================\n#=================================================================================\n#=============================  * Model  Finetuneing *  =============================\n#=================================================================================\n#=================================================================================\n#=================================================================================**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.526422Z","iopub.status.idle":"2024-01-29T08:47:13.526769Z","shell.execute_reply.started":"2024-01-29T08:47:13.526599Z","shell.execute_reply":"2024-01-29T08:47:13.526615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.527888Z","iopub.status.idle":"2024-01-29T08:47:13.528231Z","shell.execute_reply.started":"2024-01-29T08:47:13.528061Z","shell.execute_reply":"2024-01-29T08:47:13.528078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequences = [\n    \"lets go and have fun\",\n    \"i am sad today\",\n]","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.529609Z","iopub.status.idle":"2024-01-29T08:47:13.529977Z","shell.execute_reply.started":"2024-01-29T08:47:13.529795Z","shell.execute_reply":"2024-01-29T08:47:13.529817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch=tokenizer(sequences,padding=True,truncation=True,return_tensors='pt')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.530947Z","iopub.status.idle":"2024-01-29T08:47:13.531285Z","shell.execute_reply.started":"2024-01-29T08:47:13.531117Z","shell.execute_reply":"2024-01-29T08:47:13.531133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch[\"labels\"] = torch.tensor([1, 0])","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.532517Z","iopub.status.idle":"2024-01-29T08:47:13.532902Z","shell.execute_reply.started":"2024-01-29T08:47:13.532693Z","shell.execute_reply":"2024-01-29T08:47:13.532709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters())\nloss = model(**batch).loss\nloss.backward()\noptimizer.step()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.533901Z","iopub.status.idle":"2024-01-29T08:47:13.534219Z","shell.execute_reply.started":"2024-01-29T08:47:13.534057Z","shell.execute_reply":"2024-01-29T08:47:13.534071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")\nraw_datasets","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.535701Z","iopub.status.idle":"2024-01-29T08:47:13.536093Z","shell.execute_reply.started":"2024-01-29T08:47:13.535919Z","shell.execute_reply":"2024-01-29T08:47:13.535936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_train_dataset = raw_datasets[\"train\"]\nraw_train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.536919Z","iopub.status.idle":"2024-01-29T08:47:13.537261Z","shell.execute_reply.started":"2024-01-29T08:47:13.537090Z","shell.execute_reply":"2024-01-29T08:47:13.537106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer(\"This is the first sentence.\", \"This is the second one.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.538743Z","iopub.status.idle":"2024-01-29T08:47:13.539117Z","shell.execute_reply.started":"2024-01-29T08:47:13.538946Z","shell.execute_reply":"2024-01-29T08:47:13.538963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"token_type_ids are used to tell model which part is one sentence and which one is another\n\n{ \n  'input_ids': [101, 2023, 2003, 1996, 2034, 6251, 1012, 102, 2023, 2003, 1996, 2117, 2028, 1012, 102],\n  \n  **'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],**\n  \n  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n}\n","metadata":{}},{"cell_type":"code","source":"def tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.540110Z","iopub.status.idle":"2024-01-29T08:47:13.540449Z","shell.execute_reply.started":"2024-01-29T08:47:13.540280Z","shell.execute_reply":"2024-01-29T08:47:13.540296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\ntokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.541516Z","iopub.status.idle":"2024-01-29T08:47:13.541894Z","shell.execute_reply.started":"2024-01-29T08:47:13.541693Z","shell.execute_reply":"2024-01-29T08:47:13.541709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.543046Z","iopub.status.idle":"2024-01-29T08:47:13.543416Z","shell.execute_reply.started":"2024-01-29T08:47:13.543247Z","shell.execute_reply":"2024-01-29T08:47:13.543263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Collator is used for any task which should be performed on batch level,for speed boost and it is used post tokenzation task**","metadata":{}},{"cell_type":"code","source":"samples = tokenized_datasets[\"train\"][:8]\nsamples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n[len(x) for x in samples[\"input_ids\"]]","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.545002Z","iopub.status.idle":"2024-01-29T08:47:13.545355Z","shell.execute_reply.started":"2024-01-29T08:47:13.545185Z","shell.execute_reply":"2024-01-29T08:47:13.545201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch = data_collator(samples)\n{k: v.shape for k, v in batch.items()}","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.546840Z","iopub.status.idle":"2024-01-29T08:47:13.547186Z","shell.execute_reply.started":"2024-01-29T08:47:13.547016Z","shell.execute_reply":"2024-01-29T08:47:13.547032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\"test-trainer\")","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.548549Z","iopub.status.idle":"2024-01-29T08:47:13.548918Z","shell.execute_reply.started":"2024-01-29T08:47:13.548717Z","shell.execute_reply":"2024-01-29T08:47:13.548732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you want to automatically upload your model to the Hub during training, pass along push_to_hub=True","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=2)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.549854Z","iopub.status.idle":"2024-01-29T08:47:13.550199Z","shell.execute_reply.started":"2024-01-29T08:47:13.550029Z","shell.execute_reply":"2024-01-29T08:47:13.550045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,                                   #for now only save trained model path\n    train_dataset=tokenized_datasets[\"train\"],       \n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,                    # for now adding only padding on batch level\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.552238Z","iopub.status.idle":"2024-01-29T08:47:13.552582Z","shell.execute_reply.started":"2024-01-29T08:47:13.552409Z","shell.execute_reply":"2024-01-29T08:47:13.552426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.553738Z","iopub.status.idle":"2024-01-29T08:47:13.554104Z","shell.execute_reply.started":"2024-01-29T08:47:13.553932Z","shell.execute_reply":"2024-01-29T08:47:13.553947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = trainer.predict(tokenized_datasets[\"validation\"])\nprint(predictions.predictions.shape, predictions.label_ids.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.555854Z","iopub.status.idle":"2024-01-29T08:47:13.556318Z","shell.execute_reply.started":"2024-01-29T08:47:13.556075Z","shell.execute_reply":"2024-01-29T08:47:13.556097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions.predictions[0],predictions.label_ids[0],predictions.metrics","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.557608Z","iopub.status.idle":"2024-01-29T08:47:13.558076Z","shell.execute_reply.started":"2024-01-29T08:47:13.557836Z","shell.execute_reply":"2024-01-29T08:47:13.557858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\npreds = np.argmax(predictions.predictions, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.559488Z","iopub.status.idle":"2024-01-29T08:47:13.559974Z","shell.execute_reply.started":"2024-01-29T08:47:13.559714Z","shell.execute_reply":"2024-01-29T08:47:13.559735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds[1]","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.561105Z","iopub.status.idle":"2024-01-29T08:47:13.561553Z","shell.execute_reply.started":"2024-01-29T08:47:13.561323Z","shell.execute_reply":"2024-01-29T08:47:13.561345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.562964Z","iopub.status.idle":"2024-01-29T08:47:13.563440Z","shell.execute_reply.started":"2024-01-29T08:47:13.563204Z","shell.execute_reply":"2024-01-29T08:47:13.563226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    metric = evaluate.load(\"glue\", \"mrpc\")\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.564987Z","iopub.status.idle":"2024-01-29T08:47:13.565435Z","shell.execute_reply.started":"2024-01-29T08:47:13.565201Z","shell.execute_reply":"2024-01-29T08:47:13.565223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.566731Z","iopub.status.idle":"2024-01-29T08:47:13.567194Z","shell.execute_reply.started":"2024-01-29T08:47:13.566960Z","shell.execute_reply":"2024-01-29T08:47:13.566982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.568361Z","iopub.status.idle":"2024-01-29T08:47:13.568836Z","shell.execute_reply.started":"2024-01-29T08:47:13.568581Z","shell.execute_reply":"2024-01-29T08:47:13.568603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------------------------------------------------------------------------------\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n------------------------------------------------------------------------------------------\n-------------------------------      FULL TRAINING          -----------------------------\n------------------------------------------------------------------------------------------\n------------------------------------------------------------------------------------------\n------------------------------------------------------------------------------------------\n------------------------------------------------------------------------------------------\n------------------------------------------------------------------------------------------\n","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")\ncheckpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n\ndef tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.571129Z","iopub.status.idle":"2024-01-29T08:47:13.571593Z","shell.execute_reply.started":"2024-01-29T08:47:13.571347Z","shell.execute_reply":"2024-01-29T08:47:13.571371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets['train']","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.573003Z","iopub.status.idle":"2024-01-29T08:47:13.573343Z","shell.execute_reply.started":"2024-01-29T08:47:13.573183Z","shell.execute_reply":"2024-01-29T08:47:13.573198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  remove unnecessary columns \ntokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\ntokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\ntokenized_datasets.set_format(\"torch\")\ntokenized_datasets[\"train\"].column_names","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.574747Z","iopub.status.idle":"2024-01-29T08:47:13.575098Z","shell.execute_reply.started":"2024-01-29T08:47:13.574935Z","shell.execute_reply":"2024-01-29T08:47:13.574951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(\n    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n)\neval_dataloader = DataLoader(\n    tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.576586Z","iopub.status.idle":"2024-01-29T08:47:13.577124Z","shell.execute_reply.started":"2024-01-29T08:47:13.576825Z","shell.execute_reply":"2024-01-29T08:47:13.576847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.578644Z","iopub.status.idle":"2024-01-29T08:47:13.579139Z","shell.execute_reply.started":"2024-01-29T08:47:13.578885Z","shell.execute_reply":"2024-01-29T08:47:13.578908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW\n\noptimizer = AdamW(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.580767Z","iopub.status.idle":"2024-01-29T08:47:13.581249Z","shell.execute_reply.started":"2024-01-29T08:47:13.581002Z","shell.execute_reply":"2024-01-29T08:47:13.581024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import get_scheduler\n\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)\nprint(num_training_steps)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.583082Z","iopub.status.idle":"2024-01-29T08:47:13.583581Z","shell.execute_reply.started":"2024-01-29T08:47:13.583338Z","shell.execute_reply":"2024-01-29T08:47:13.583360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.586165Z","iopub.status.idle":"2024-01-29T08:47:13.586491Z","shell.execute_reply.started":"2024-01-29T08:47:13.586317Z","shell.execute_reply":"2024-01-29T08:47:13.586332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()} \n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.587409Z","iopub.status.idle":"2024-01-29T08:47:13.587828Z","shell.execute_reply.started":"2024-01-29T08:47:13.587613Z","shell.execute_reply":"2024-01-29T08:47:13.587631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"glue\", \"mrpc\")\nmodel.eval()\nfor batch in eval_dataloader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch) \n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n\nmetric.compute()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.589011Z","iopub.status.idle":"2024-01-29T08:47:13.589337Z","shell.execute_reply.started":"2024-01-29T08:47:13.589175Z","shell.execute_reply":"2024-01-29T08:47:13.589191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\noptimizer = AdamW(model.parameters(), lr=3e-5)\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\n\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)\n\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.590990Z","iopub.status.idle":"2024-01-29T08:47:13.591372Z","shell.execute_reply.started":"2024-01-29T08:47:13.591188Z","shell.execute_reply":"2024-01-29T08:47:13.591206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"following is the whole code for training on single cpu/gpu\n-----------------------------------------------------------------------------------\nfrom transformers import AdamW, AutoModelForSequenceClassification, get_scheduler\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\noptimizer = AdamW(model.parameters(), lr=3e-5)\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\n\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)\n\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)\n        \n-----------------------------------------------------------------------\nfollowing is the updated version for Training accross multiple CPU,GPU\n------------------------------------------------------------------------\n\n","metadata":{}},{"cell_type":"code","source":"\n+ from accelerate import Accelerator\n  from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler\n\n+ accelerator = Accelerator()\n\n  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n  optimizer = AdamW(model.parameters(), lr=3e-5)\n\n- device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n- model.to(device)\n\n+ train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(\n+     train_dataloader, eval_dataloader, model, optimizer\n+ )\n\n  num_epochs = 3\n  num_training_steps = num_epochs * len(train_dataloader)\n  lr_scheduler = get_scheduler(\n      \"linear\",\n      optimizer=optimizer,\n      num_warmup_steps=0,\n      num_training_steps=num_training_steps\n  )\n\n  progress_bar = tqdm(range(num_training_steps))\n\n  model.train()\n  for epoch in range(num_epochs):\n      for batch in train_dataloader:\n-         batch = {k: v.to(device) for k, v in batch.items()}\n          outputs = model(**batch)\n          loss = outputs.loss\n-         loss.backward()\n+         accelerator.backward(loss)\n\n          optimizer.step()\n          lr_scheduler.step()\n          optimizer.zero_grad()\n          progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.592803Z","iopub.status.idle":"2024-01-29T08:47:13.593189Z","shell.execute_reply.started":"2024-01-29T08:47:13.592997Z","shell.execute_reply":"2024-01-29T08:47:13.593014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"whole updated code\n------------------------------------------","metadata":{}},{"cell_type":"code","source":"from accelerate import Accelerator\nfrom transformers import AdamW, AutoModelForSequenceClassification, get_scheduler\n\naccelerator = Accelerator()\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\noptimizer = AdamW(model.parameters(), lr=3e-5)\n\ntrain_dl, eval_dl, model, optimizer = accelerator.prepare(\n    train_dataloader, eval_dataloader, model, optimizer\n)\n\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dl)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)\n\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in range(num_epochs):\n    for batch in train_dl:\n        outputs = model(**batch)\n        loss = outputs.loss\n        accelerator.backward(loss)\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.594313Z","iopub.status.idle":"2024-01-29T08:47:13.594639Z","shell.execute_reply.started":"2024-01-29T08:47:13.594467Z","shell.execute_reply":"2024-01-29T08:47:13.594483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"above script can be put as a .py file and accelarate can be used for training on any device\n---------------\ncmd\n-----\naccelerate config \n------\naccelerate launch train.py\n-----","metadata":{}},{"cell_type":"markdown","source":"If you want to try this in a Notebook (for instance, to test it with TPUs on Colab), just paste the code in a training_function() and run a last cell with:\n\nCopied\n\nfrom accelerate import notebook_launcher\n---------------------------------------\nnotebook_launcher(training_function)\n--------------------------------------","metadata":{}},{"cell_type":"code","source":"# loading dataset file form remote server \nurl = \"https://github.com/crux82/squad-it/raw/master/\"\ndata_files = {\n    \"train\": url + \"SQuAD_it-train.json.gz\",\n    \"test\": url + \"SQuAD_it-test.json.gz\",\n}\nsquad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:47:13.596023Z","iopub.status.idle":"2024-01-29T08:47:13.596348Z","shell.execute_reply.started":"2024-01-29T08:47:13.596181Z","shell.execute_reply":"2024-01-29T08:47:13.596196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_and_split(examples):\n    return tokenizer(\n        examples[\"review\"],\n        truncation=True,\n        max_length=128,\n        return_overflowing_tokens=True, #this is used for return all the trucated token after max_length\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drug_dataset_clean.save_to_disk(\"drug-reviews\")\n# used for saving preprocessed data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}